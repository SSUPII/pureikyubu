// AnalyzeInfo structure definitions for X86-16, X86-32, and X64 architectures.
// There is no instruction analyzer (decoder) here yet.

// Everything related to Intel VT, SGX and other similar things is not supported.

#pragma once

namespace IntelCore
{

	/// <summary>
	/// List of Intel instructions for all architectures. 
	/// </summary>
	enum class Instruction : int
	{
		Unknown = -1,

		// General-Purpose Instructions

		mov,
		mov_sr,				// Move to/from Segment Registers
		cmove,
		cmovz = cmove,
		cmovne,
		cmovnz = cmovne,
		cmova,
		cmovnbe = cmova,
		cmovae,
		cmovnb = cmovae,
		cmovb,
		cmovnae = cmovb,
		cmovbe,
		cmovna = cmovbe,
		cmovg,
		cmovnle = cmovg,
		cmovge,
		cmovnl = cmovge,
		cmovl,
		cmovnge = cmovl,
		cmovle,
		cmovng = cmovle,
		cmovc,
		cmovnc,
		cmovo,
		cmovno,
		cmovs,
		cmovns,
		cmovp,
		cmovpe = cmovp,
		cmovnp,
		cmovpo = cmovnp,
		xchg,
		bswap,
		xadd,
		cmpxchg,
		cmpxchg8b,
		push,
		push_sr,			// Push Segment Register onto the Stack
		pop,
		pop_sr,				// Pop a Segment Register from the Stack
		pusha,
		pushad,
		popa,
		popad,
		cwd,
		cdq,
		cqo,
		cbw,
		cwde,
		cdqe,
		movsx,
		movsxd,
		movzx,
		adcx,
		adox,
		add,
		adc,
		sub,
		sbb,
		imul,
		mul,
		idiv,
		div,
		inc,
		dec,
		neg,
		cmp,
		daa,
		das,
		aaa,
		aas,
		aam,
		aad,
		_and,
		_or,
		_xor,
		_not,
		sar,
		shr,
		sal,
		shl,
		shrd,
		shld,
		ror,
		rol,
		rcr,
		rcl,
		bt,
		bts,
		btr,
		btc,
		bsf,
		bsr,
		sete,
		setz = sete,
		setne,
		setnz = setne,
		seta,
		setnbe = seta,
		setae,
		setnb = setae,
		setnc = setae,
		setb,
		setnae = setb,
		setc = setb,
		setbe,
		setna = setbe,
		setg,
		setnle = setg,
		setge,
		setnl = setge,
		setl,
		setnge = setl,
		setle,
		setng = setle,
		sets,
		setns,
		seto,
		setno,
		setpe,
		setp = setpe,
		setpo,
		setnp = setpo,
		test,
		crc32,
		popcnt,
		jmp,				// in same segment
		jmpfar,				// in other segment
		je,
		jz = je,
		jne,
		jnz = jne,
		ja ,
		jnbe = ja,
		jae,
		jnb = jae,
		jb,
		jnae = jb,
		jbe,
		jna = jbe,
		jg, 
		jnle = jg,
		jge, 
		jnl = jge,
		jl, 
		jnge = jl,
		jle, 
		jng = jle,
		jc,
		jnc,
		jo,
		jno,
		js,
		jns,
		jpo,
		jnp = jpo,
		jpe, 
		jp = jpe,
		jcxz, 
		jecxz = jcxz,
		loop,
		loopz, 
		loope = loopz,
		loopnz, 
		loopne = loopnz,
		call,				// in same segment
		callfar,			// in other segment
		ret,				// in same segment
		retfar,				// in other segment
		iret,
		iretd,
		iretq,
		_int,
		int3,
		into,
		int1,
		bound,
		enter,
		leave,
		movsb,
		movsw,
		movsd,
		movsq,
		cmpsb,
		cmpsw,
		cmpsd,
		cmpsq,
		scasb,
		scasw,
		scasd,
		scasq,
		lodsb,
		lodsw,
		lodsd,
		lodsq,
		stosb,
		stosw,
		stosd,
		stosq,
		//rep,					// Treated as a prefix 
		//repe,					// Treated as a prefix 
		//repz = repe,			// Treated as a prefix 
		//repne,				// Treated as a prefix 
		//repnz = repne,		// Treated as a prefix 
		in,
		out,
		insb,
		insw,
		insd,
		outsb,
		outsw,
		outsd,
		stc,
		clc,
		cmc,
		cld,
		std,
		lahf,
		sahf,
		pushf,
		pushfd,
		pushfq,
		popf,
		popfd,
		popfq,
		sti,
		cli,
		lds,
		les,
		lfs,
		lgs,
		lss,
		lea,
		nop,
		ud0,
		ud1,
		ud2,
		xlat,
		xlatb = xlat,
		cpuid,
		movbe,
		prefetchw,
		prefetchwt1,
		clflush,
		clflushopt,
		rdrand,
		rdseed,

		// System Instructions

		clac,
		stac,
		lgdt,
		sgdt,
		lldt,
		sldt,
		ltr,
		str,
		lidt,
		sidt,
		mov_cr,				// Move to/from Control Registers
		lmsw,
		smsw,
		clts,
		arpl,
		lar,
		lsl,
		verr,
		verw,
		mov_dr,				// MOV – Move to/from Debug Registers
		invd,
		wbinvd,
		invlpg,
		invpcid,
		//lock,				// Treated as a prefix 
		hlt,
		rsm,
		rdmsr,
		wrmsr,
		rdpmc,
		rdtsc,
		rdtscp,
		sysenter,
		sysexit,
		xsave,
		xsavec,
		xsaveopt,
		xsaves,
		xrstor,
		xrstors,
		xgetbv,
		xsetbv,
		rdfsbase,
		rdgsbase,
		wrfsbase,
		wrgsbase,
		swapgs,
		syscall,
		sysret,
		sysretq,

		// 64-Bit Mode Instructions

		cmpxchg16b,
		movzx_64,

		// BMI1, BMI2

		andn,
		bextr,
		blsi,
		blsmsk,
		blsr,
		bzhi,
		lzcnt,
		mulx,
		pdep,
		pext,
		rorx,
		sarx,
		shlx,
		shrx,
		tzcnt,

		// x87 FPU Instructions

		fld,
		fst,
		fstp,
		fild,
		fist,
		fistp,
		fbld,
		fbstp,
		fxch,
		fcmove,
		fcmovne,
		fcmovb,
		fcmovbe,
		fcmovnb,
		fcmovnbe,
		fcmovu,
		fcmovnu,
		fadd,
		faddp,
		fiadd,
		fsub,
		fsubp,
		fisub,
		fsubr,
		fsubrp,
		fisubr,
		fmul,
		fmulp,
		fimul,
		fdiv,
		fdivp,
		fidiv,
		fdivr,
		fdivrp,
		fidivr,
		fprem,
		fprem1,
		fabs,
		fchs,
		frndint,
		fscale,
		fsqrt,
		fxtract,
		fcom,
		fcomp,
		fcompp,
		fucom,
		fucomp,
		fucompp,
		ficom,
		ficomp,
		fcomi,
		fucomi,
		fcomip,
		fucomip,
		ftst,
		fxam,
		fsin,
		fcos,
		fsincos,
		fptan,
		fpatan,
		f2xm1,
		fyl2x,
		fyl2xp1,
		fld1,
		fldz,
		fldpi,
		fldl2e,
		fldln2,
		fldl2t,
		fldlg2,
		fincstp,
		fdecstp,
		ffree,
		finit,
		fninit,
		fclex,
		fnclex,
		fstcw,
		fnstcw,
		fldcw,
		fstenv,
		fnstenv,
		fldenv,
		fsave,
		fnsave,
		frstor,
		fstsw,
		fnstsw,
		wait,
		fwait = wait,
		fnop,
		fxsave,
		fxrstor,

		// MMX™ Instructions

		movd,
		movq,
		packsswb,
		packssdw,
		packuswb,
		punpckhbw,
		punpckhwd,
		punpckhdq,
		punpcklbw,
		punpcklwd,
		punpckldq,
		paddb,
		paddw,
		paddd,
		paddsb,
		paddsw,
		paddusb,
		paddusw,
		psubb,
		psubw,
		psubd,
		psubsb,
		psubsw,
		psubusb,
		psubusw,
		pmulhw,
		pmullw,
		pmaddwd,
		pcmpeqb,
		pcmpeqw,
		pcmpeqd,
		pcmpgtb,
		pcmpgtw,
		pcmpgtd,
		pand,
		pandn,
		por,
		pxor,
		psllw,
		pslld,
		psllq,
		psrlw,
		psrld,
		psrlq,
		psraw,
		psrad,
		emms,

		// TODO: The definitions of SSE/AVX instructions now look a little chaotic, when it comes to them they will be put in order.

		// SSE (™?) Instructions

		movaps,
		movups,
		movhps,
		movhlps,
		movlps,
		movlhps,
		movmskps,
		movss,
		addps,
		addss,
		subps,
		subss,
		mulps,
		mulss,
		divps,
		divss,
		rcpps,
		rcpss,
		sqrtps,
		sqrtss,
		rsqrtps,
		rsqrtss,
		maxps,
		maxss,
		minps,
		minss,
		cmpps,
		cmpss,
		comiss,
		ucomiss,
		andps,
		andnps,
		orps,
		xorps,
		shufps,
		unpckhps,
		unpcklps,
		cvtpi2ps,
		cvtsi2ss,
		cvtps2pi,
		cvttps2pi,
		cvtss2si,
		cvttss2si,
		ldmxcsr,
		stmxcsr,
		pavgb,
		pavgw,
		pextrw,
		pinsrw,
		pmaxub,
		pmaxsw,
		pminub,
		pminsw,
		pmovmskb,
		pmulhuw,
		psadbw,
		pshufw,
		maskmovq,
		movntq,
		movntps,
		prefetchh,
		sfence,

		// SSE2 Instructions

		movapd,
		movupd,
		movhpd,
		movlpd,
		movmskpd,
		movsd_sse,
		addpd,
		addsd,
		subpd,
		subsd,
		mulpd,
		mulsd,
		divpd,
		divsd,
		sqrtpd,
		sqrtsd,
		maxpd,
		maxsd,
		minpd,
		minsd,
		andpd,
		andnpd,
		orpd,
		xorpd,
		cmppd,
		cmpsd_sse,
		comisd,
		ucomisd,
		shufpd,
		unpckhpd,
		unpcklpd,
		cvtpd2pi,
		cvttpd2pi,
		cvtpi2pd,
		cvtpd2dq,
		cvttpd2dq,
		cvtdq2pd,
		cvtps2pd,
		cvtpd2ps,
		cvtss2sd,
		cvtsd2ss,
		cvtsd2si,
		cvttsd2si,
		cvtsi2sd,
		cvtdq2ps,
		cvtps2dq,
		cvttps2dq,
		movdqa,
		movdqu,
		movq2dq,
		movdq2q,
		pmuludq,
		paddq,
		psubq,
		pshuflw,
		pshufhw,
		pshufd,
		pslldq,
		psrldq,
		punpckhqdq,
		punpcklqdq,
		lfence,
		mfence,
		pause,
		maskmovdqu,
		movntpd,
		movntdq,
		movnti,

		// SSE3 Instructions

		fisttp,
		lddqu,
		addsubps,
		addsubpd,
		haddps,
		hsubps,
		haddpd,
		hsubpd,
		movshdup,
		movsldup,
		movddup,
		monitor,
		mwait,

		// Supplemental Streaming SIMD Extensions 3 (SSSE3) Instructions

		phaddw,
		phaddsw,
		phaddd,
		phsubw,
		phsubsw,
		phsubd,
		pabsb,
		pabsw,
		pabsd,
		pmaddubsw,
		pmulhrsw,
		pshufb,
		psignb,
		psignw,
		psignd,
		palignr,

		// SSE4.1 Instructions

		pmulld,
		pmuldq,
		dppd,
		dpps,
		movntdqa,
		blendpd,
		blendps,
		blendvpd,
		blendvps,
		pblendvb,
		pblendw,
		pminuw,
		pminud,
		pminsb,
		pminsd,
		pmaxuw,
		pmaxud,
		pmaxsb,
		pmaxsd,
		roundps,
		roundpd,
		roundss,
		roundsd,
		extractps,
		insertps,
		pinsrb,
		pinsrd,
		pinsrq,
		pextrb,
		pextrd,
		pextrq,
		pmovsxbw,
		pmovzxbw,
		pmovsxbd,
		pmovzxbd,
		pmovsxwd,
		pmovzxwd,
		pmovsxbq,
		pmovzxbq,
		pmovsxwq,
		pmovzxwq,
		pmovsxdq,
		pmovzxdq,
		mpsadbw,
		phminposuw,
		ptest,
		pcmpeqq,
		packusdw,

		// SSE4.2 Instruction Set

		pcmpestri,
		pcmpestrm,
		pcmpistri,
		pcmpistrm,
		pcmpgtq,

		// Intel® AES-NI and PCLMULQDQ

		aesdec,
		aesdeclast,
		aesenc,
		aesenclast,
		aesimc,
		aeskeygenassist,
		pclmulqdq,

		// Intel® Advanced Vector Extensions (Intel® AVX)

		// TBD

		// 16-bit Floating-Point Conversion

		vcvtph2ps,
		vcvtps2ph,

		// Fused-Multiply-ADD (FMA)

		vfmadd132pd,
		vfmadd213pd,
		vfmadd231pd,
		vfmadd132ps,
		vfmadd213ps,
		vfmadd231ps,
		vfmadd132sd,
		vfmadd213sd,
		vfmadd231sd,
		vfmadd132ss,
		vfmadd213ss,
		vfmadd231ss,
		vfmaddsub132pd,
		vfmaddsub213pd,
		vfmaddsub231pd,
		vfmaddsub132ps,
		vfmaddsub213ps,
		vfmaddsub231ps,
		vfmsubadd132pd,
		vfmsubadd213pd,
		vfmsubadd231pd,
		vfmsubadd132ps,
		vfmsubadd213ps,
		vfmsubadd231ps,
		vfmsub132pd,
		vfmsub213pd,
		vfmsub231pd,
		vfmsub132ps,
		vfmsub213ps,
		vfmsub231ps,
		vfmsub132sd,
		vfmsub213sd,
		vfmsub231sd,
		vfmsub132ss,
		vfmsub213ss,
		vfmsub231ss,
		vfnmadd132pd,
		vfnmadd213pd,
		vfnmadd231pd,
		vfnmadd132ps,
		vfnmadd213ps,
		vfnmadd231ps,
		vfnmadd132sd,
		vfnmadd213sd,
		vfnmadd231sd,
		vfnmadd132ss,
		vfnmadd213ss,
		vfnmadd231ss,
		vfnmsub132pd,
		vfnmsub213pd,
		vfnmsub231pd,
		vfnmsub132ps,
		vfnmsub213ps,
		vfnmsub231ps,
		vfnmsub132sd,
		vfnmsub213sd,
		vfnmsub231sd,
		vfnmsub132ss,
		vfnmsub213ss,
		vfnmsub231ss,

		// Intel® Advanced Vector Extensions 2 (Intel® AVX2)

		// TBD

		// Intel® Advanced Vector Extensions 512 (Intel® AVX-512)

		valignd,
		valignq,
		vblendmpd,
		vblendmps,
		vcompresspd,
		vcompressps,
		vcvtpd2udq,
		vcvttpd2udq,
		vcvtps2udq,
		vcvttps2udq,
		vcvtqq2pd,
		vcvtqq2ps,
		vcvtsd2usi,
		vcvttsd2usi,
		vcvtss2usi,
		vcvttss2usi,
		vcvtudq2pd,
		vcvtudq2ps,
		vcvtusi2usd,
		vcvtusi2uss,
		vexpandpd,
		vexpandps,
		vextractf32x4,
		vextractf64x4,
		vextracti32x4,
		vextracti64x4,
		vfixupimmpd, 
		vfixupimmps,
		vfixupimmsd,
		vfixupimmss,
		vgetexppd,
		vgetexpps,
		vgetexpsd,
		vgetexpss,
		vgetmantpd,
		vgetmantps,
		vgetmantsd,
		vgetmantss,
		vinsertf32x4,
		vinsertf64x4,
		vmovdqa32,
		vmovdqa64,
		vmovdqu32,
		vmovdqu64,
		vpblendmd,
		vpblendmq,
		vpcmpd,
		vpcmud,
		vpcmpq,
		vpcmuq,
		vpcompressq,
		vpcompressd,
		vpermi2d,
		vpermi2q,
		vpermi2pd, 
		vpermi2ps,
		vpermt2d,
		vpermt2q,
		vpermt2pd, 
		vpermt2ps,
		vpexpandd,
		vpexpandq,
		vpmaxsq,
		vpmaxud,
		vpmaxuq,
		vpminsq,
		vpminud,
		vpminuq,
		vpmovqb,
		vpmovsqb,
		vpmovusqb,
		vpmovqw,
		vpmovsqw,
		vpmovusqw,
		vpmovqd,
		vpmovsqd,
		vpmovusqd,
		vpmovdb,
		vpmovsdb,
		vpmovusdb,
		vpmovdw,
		vpscatterdd,
		vpscatterdq,
		vpscatterqd,
		vpscatterqq,
		vpsraq,
		vpsravq,
		vptestnmd,
		vptestnmq,
		vpterlogd,
		vpterlogq,
		vpbroadcastd,
		vpbroadcastq,
		vpmovsdw,
		vpmovusdw,
		vprold,
		vprolq,
		vprolvd,
		vprolvq,
		vprord,
		vprorq,
		vprorrd,
		vprorrq,
		vcvtpd2qq,
		vcvttpd2qq,
		vcvtpd2uqq,
		vcvttpd2uqq,
		vcvtps2qq,
		vcvttps2qq,
		vcvtps2uqq,
		vcvttps2uqq,
		vcvtuqq2pd,
		vcvtuqq2ps,
		vextractf64x2,
		vextracti64x2,
		vfpclasspd,
		vfpclassps,
		vfpclasssd,
		vfpclassss,
		vinsertf64x2,
		vinserti64x2,
		vpmovm2d,
		vpmovm2q,
		vpmovb2d,
		vpmovq2m,
		vpmullq,
		vrangepd,
		vrangeps,
		vrangesd,
		vrangess,
		vreducepd,
		vreduceps,
		vreducesd,
		vreducess,
		vdbpsadbw,
		vmovdqu8,
		vmovdqu16,
		vpblendmb,
		vpblendmw,
		vpbroadcastb,
		vpbroadcastw,
		vpcmpb,
		vpcmub,
		vpcmpw,
		vpcmuw,
		vpermw,
		vpermi2b,
		vpermi2w,
		vpmovm2b,
		vpmovm2w,
		vpmovb2m,
		vpmovw2m,
		vpmovwb,
		vpmovswb,
		vpmovuswb,
		vpsllvw,
		vpsravw,
		vpsrlvw,
		vptestnmb,
		vptestnmw,
		vptestmb,
		vptestmw,
		vpbroadcastm,
		vpconflictd,
		vpconflictq,
		vplzcntd,
		vplzcntq,
		kaddb,
		kaddw,
		kaddd,
		kaddq,
		kandb,
		kandw,
		kandd,
		kandq,
		kandnb,
		kandnw,
		kandnd,
		kandnq,
		kmovb,
		kmovw,
		kmovd,
		kmovq,
		knotb,
		knotw,
		knotd,
		knotq,
		korb,
		korw,
		kord,
		korq,
		kortestb,
		kortestw,
		kortestd,
		kortestq,
		kshiftlb,
		kshiftlw,
		kshiftld,
		kshiftlq,
		kshiftrb,
		kshiftrw,
		kshiftrd,
		kshiftrq,
		ktestb,
		ktestw,
		ktestd,
		ktestq,
		kunpckbw,
		kunpckbwd,
		kunpckbwq,
		kxnorb,
		kxnorw,
		kxnord,
		kxnorq,
		kxorb,
		kxorw,
		kxord,
		kxorq,
		vexp2pd,
		vexp2ps,
		vexp2sd,
		vexp2ss,
		vrcp28pd,
		vrcp28ps,
		vrcp28sd,
		vrcp28ss,
		vrsqrt28pd,
		vrsqrt28ps,
		vrsqrt28sd,
		vrsqrt28ss,
		vgatherpf0dpd,
		vgatherpf0dps,
		vgatherpf0qpd,
		vgatherpf0qps,
		vgatherpf1dpd,
		vgatherpf1dps,
		vgatherpf1qpd,
		vgatherpf1qps,
		vscatterpf0dpd,
		vscatterpf0dps,
		vscatterpf0qpd,
		vscatterpf0qps,
		vscatterpf1dpd,
		vscatterpf1dps,
		vscatterpf1qpd,
		vscatterpf1qps,

	};

	/// <summary>
	/// Used to set the instruction prefixes.
	/// </summary>
	enum class Prefix : int
	{
		NoPrefix = 0,
		AddressSize,	// 0x67
		Lock,
		OperandSize,    // 0x66
		SegCs,
		SegDs,
		SegEs,
		SegFs,
		SegGs,
		SegSs,
		Rep,
		Repe,
		Repz = Repe,
		Repne,
		Repnz = Repne,
	};

	/// <summary>
	/// Category of instructions for additional analysis. 
	/// Of greatest interest are the instructions in the FlowControl category, which affect the construction of a call graph (for example). 
	/// </summary>
	enum class Category : int
	{
		NothingSpecial = 0,		// Nothing special
		FlowControl,			// The instruction can change the flow of execution (jmp, call, ret, etc.) 
		Fpu,					// x87 FPU Instruction
		Mmx,					// MMX Instruction
		Sse,					// SSE (any) Instruction
		Avx,					// AVX (any) Instruction
	};

	/// <summary>
	/// One of the parameters 
	/// </summary>
	enum class Param : int
	{
		Unknown = -1,

		// Special constants to quickly define the category of a parameter. Do not use. 

		ImmediateStart = 0,
		RegStart = 0x200,
		MemStart = 0x400,

		// immediate

		imm8 = ImmediateStart,
		imm16,
		imm32,
		ImmediateEnd = 0x100,

		// reg

		al = RegStart, cl, dl, bl, ah, ch, dh, bh,
		ax, cx, dx, bx, sp, bp, si, di,
		eax, ecx, edx, ebx, esp, ebp, esi, edi,
		RegEnd = 0x300,

		// 16-bit mem
		// If you need memory addressing like [BP + DI] and so on. similar, look here.

		m_bx_si = MemStart, m_bx_di, m_bp_si, m_bp_di, m_si, m_di, m_disp16 /* disp16 instead bp */, m_bx,
		m_bx_si_disp8, m_bx_di_disp8, m_bp_si_disp8, m_bp_di_disp8, m_si_disp8, m_di_disp8, m_bp_disp8, m_bx_disp8,
		m_bx_si_disp16, m_bx_di_disp16, m_bp_si_disp16, m_bp_di_disp16, m_si_disp16, m_di_disp16, m_bp_disp16, m_bx_disp16,

		// 32-bit mem
		// If you need simple 32-bit addressing like [ESI], see here. 

		m_eax, m_ecx, m_edx, m_ebx, /*see sib_, */ m_disp32, m_esi, m_edi,
		m_eax_disp8, m_ecx_disp8, m_edx_disp8, m_ebx_disp8, /*see sib_x_disp8, */ m_disp32_disp8, m_esi_disp8, m_edi_disp8,
		m_eax_disp32, m_ecx_disp32, m_edx_disp32, m_ebx_disp32, /*see sib_x_disp32, */ m_disp32_disp32, m_esi_disp32, m_edi_disp32,

		// If you need 32-bit addressing using the ScaleIndexBase mechanism like [EAX * 2 + ECX], see here. 

		sib_eax_eax, sib_eax_ecx, sib_eax_edx, sib_eax_ebx, sib_eax_esp, sib_eax_disp32 /* disp32 instead ebp */, sib_eax_esi, sib_eax_edi,
		sib_ecx_eax, sib_ecx_ecx, sib_ecx_edx, sib_ecx_ebx, sib_ecx_esp, sib_ecx_disp32 /* disp32 instead ebp */, sib_ecx_esi, sib_ecx_edi,
		sib_edx_eax, sib_edx_ecx, sib_edx_edx, sib_edx_ebx, sib_edx_esp, sib_edx_disp32 /* disp32 instead ebp */, sib_edx_esi, sib_edx_edi,
		sib_ebx_eax, sib_ebx_ecx, sib_ebx_edx, sib_ebx_ebx, sib_ebx_esp, sib_ebx_disp32 /* disp32 instead ebp */, sib_ebx_esi, sib_ebx_edi,
		sib_none_eax, sib_none_ecx, sib_none_edx, sib_none_ebx, sib_none_esp, sib_none_disp32 /* disp32 instead ebp */, sib_none_esi, sib_none_edi,
		sib_ebp_eax, sib_ebp_ecx, sib_ebp_edx, sib_ebp_ebx, sib_ebp_esp, sib_ebp_disp32 /* disp32 instead ebp */, sib_ebp_esi, sib_ebp_edi,
		sib_esi_eax, sib_esi_ecx, sib_esi_edx, sib_esi_ebx, sib_esi_esp, sib_esi_disp32 /* disp32 instead ebp */, sib_esi_esi, sib_esi_edi,
		sib_edi_eax, sib_edi_ecx, sib_edi_edx, sib_edi_ebx, sib_edi_esp, sib_edi_disp32 /* disp32 instead ebp */, sib_edi_esi, sib_edi_edi,

		sib_eax_2_eax, sib_eax_2_ecx, sib_eax_2_edx, sib_eax_2_ebx, sib_eax_2_esp, sib_eax_2_disp32 /* disp32 instead ebp */, sib_eax_2_esi, sib_eax_2_edi,
		sib_ecx_2_eax, sib_ecx_2_ecx, sib_ecx_2_edx, sib_ecx_2_ebx, sib_ecx_2_esp, sib_ecx_2_disp32 /* disp32 instead ebp */, sib_ecx_2_esi, sib_ecx_2_edi,
		sib_edx_2_eax, sib_edx_2_ecx, sib_edx_2_edx, sib_edx_2_ebx, sib_edx_2_esp, sib_edx_2_disp32 /* disp32 instead ebp */, sib_edx_2_esi, sib_edx_2_edi,
		sib_ebx_2_eax, sib_ebx_2_ecx, sib_ebx_2_edx, sib_ebx_2_ebx, sib_ebx_2_esp, sib_ebx_2_disp32 /* disp32 instead ebp */, sib_ebx_2_esi, sib_ebx_2_edi,
		sib_ebp_2_eax, sib_ebp_2_ecx, sib_ebp_2_edx, sib_ebp_2_ebx, sib_ebp_2_esp, sib_ebp_2_disp32 /* disp32 instead ebp */, sib_ebp_2_esi, sib_ebp_2_edi,
		sib_esi_2_eax, sib_esi_2_ecx, sib_esi_2_edx, sib_esi_2_ebx, sib_esi_2_esp, sib_esi_2_disp32 /* disp32 instead ebp */, sib_esi_2_esi, sib_esi_2_edi,
		sib_edi_2_eax, sib_edi_2_ecx, sib_edi_2_edx, sib_edi_2_ebx, sib_edi_2_esp, sib_edi_2_disp32 /* disp32 instead ebp */, sib_edi_2_esi, sib_edi_2_edi,

		sib_eax_4_eax, sib_eax_4_ecx, sib_eax_4_edx, sib_eax_4_ebx, sib_eax_4_esp, sib_eax_4_disp32 /* disp32 instead ebp */, sib_eax_4_esi, sib_eax_4_edi,
		sib_ecx_4_eax, sib_ecx_4_ecx, sib_ecx_4_edx, sib_ecx_4_ebx, sib_ecx_4_esp, sib_ecx_4_disp32 /* disp32 instead ebp */, sib_ecx_4_esi, sib_ecx_4_edi,
		sib_edx_4_eax, sib_edx_4_ecx, sib_edx_4_edx, sib_edx_4_ebx, sib_edx_4_esp, sib_edx_4_disp32 /* disp32 instead ebp */, sib_edx_4_esi, sib_edx_4_edi,
		sib_ebx_4_eax, sib_ebx_4_ecx, sib_ebx_4_edx, sib_ebx_4_ebx, sib_ebx_4_esp, sib_ebx_4_disp32 /* disp32 instead ebp */, sib_ebx_4_esi, sib_ebx_4_edi,
		sib_ebp_4_eax, sib_ebp_4_ecx, sib_ebp_4_edx, sib_ebp_4_ebx, sib_ebp_4_esp, sib_ebp_4_disp32 /* disp32 instead ebp */, sib_ebp_4_esi, sib_ebp_4_edi,
		sib_esi_4_eax, sib_esi_4_ecx, sib_esi_4_edx, sib_esi_4_ebx, sib_esi_4_esp, sib_esi_4_disp32 /* disp32 instead ebp */, sib_esi_4_esi, sib_esi_4_edi,
		sib_edi_4_eax, sib_edi_4_ecx, sib_edi_4_edx, sib_edi_4_ebx, sib_edi_4_esp, sib_edi_4_disp32 /* disp32 instead ebp */, sib_edi_4_esi, sib_edi_4_edi,

		sib_eax_8_eax, sib_eax_8_ecx, sib_eax_8_edx, sib_eax_8_ebx, sib_eax_8_esp, sib_eax_8_disp32 /* disp32 instead ebp */, sib_eax_8_esi, sib_eax_8_edi,
		sib_ecx_8_eax, sib_ecx_8_ecx, sib_ecx_8_edx, sib_ecx_8_ebx, sib_ecx_8_esp, sib_ecx_8_disp32 /* disp32 instead ebp */, sib_ecx_8_esi, sib_ecx_8_edi,
		sib_edx_8_eax, sib_edx_8_ecx, sib_edx_8_edx, sib_edx_8_ebx, sib_edx_8_esp, sib_edx_8_disp32 /* disp32 instead ebp */, sib_edx_8_esi, sib_edx_8_edi,
		sib_ebx_8_eax, sib_ebx_8_ecx, sib_ebx_8_edx, sib_ebx_8_ebx, sib_ebx_8_esp, sib_ebx_8_disp32 /* disp32 instead ebp */, sib_ebx_8_esi, sib_ebx_8_edi,
		sib_ebp_8_eax, sib_ebp_8_ecx, sib_ebp_8_edx, sib_ebp_8_ebx, sib_ebp_8_esp, sib_ebp_8_disp32 /* disp32 instead ebp */, sib_ebp_8_esi, sib_ebp_8_edi,
		sib_esi_8_eax, sib_esi_8_ecx, sib_esi_8_edx, sib_esi_8_ebx, sib_esi_8_esp, sib_esi_8_disp32 /* disp32 instead ebp */, sib_esi_8_esi, sib_esi_8_edi,
		sib_edi_8_eax, sib_edi_8_ecx, sib_edi_8_edx, sib_edi_8_ebx, sib_edi_8_esp, sib_edi_8_disp32 /* disp32 instead ebp */, sib_edi_8_esi, sib_edi_8_edi,

		sib_eax_eax_disp8, sib_eax_ecx_disp8, sib_eax_edx_disp8, sib_eax_ebx_disp8, sib_eax_esp_disp8, sib_eax_ebp_disp8, sib_eax_esi_disp8, sib_eax_edi_disp8,
		sib_ecx_eax_disp8, sib_ecx_ecx_disp8, sib_ecx_edx_disp8, sib_ecx_ebx_disp8, sib_ecx_esp_disp8, sib_ecx_ebp_disp8, sib_ecx_esi_disp8, sib_ecx_edi_disp8,
		sib_edx_eax_disp8, sib_edx_ecx_disp8, sib_edx_edx_disp8, sib_edx_ebx_disp8, sib_edx_esp_disp8, sib_edx_ebp_disp8, sib_edx_esi_disp8, sib_edx_edi_disp8,
		sib_ebx_eax_disp8, sib_ebx_ecx_disp8, sib_ebx_edx_disp8, sib_ebx_ebx_disp8, sib_ebx_esp_disp8, sib_ebx_ebp_disp8, sib_ebx_esi_disp8, sib_ebx_edi_disp8,
		sib_none_eax_disp8, sib_none_ecx_disp8, sib_none_edx_disp8, sib_none_ebx_disp8, sib_none_esp_disp8, sib_none_ebp_disp8, sib_none_esi_disp8, sib_none_edi_disp8,
		sib_ebp_eax_disp8, sib_ebp_ecx_disp8, sib_ebp_edx_disp8, sib_ebp_ebx_disp8, sib_ebp_esp_disp8, sib_ebp_ebp_disp8, sib_ebp_esi_disp8, sib_ebp_edi_disp8,
		sib_esi_eax_disp8, sib_esi_ecx_disp8, sib_esi_edx_disp8, sib_esi_ebx_disp8, sib_esi_esp_disp8, sib_esi_ebp_disp8, sib_esi_esi_disp8, sib_esi_edi_disp8,
		sib_edi_eax_disp8, sib_edi_ecx_disp8, sib_edi_edx_disp8, sib_edi_ebx_disp8, sib_edi_esp_disp8, sib_edi_ebp_disp8, sib_edi_esi_disp8, sib_edi_edi_disp8,

		sib_eax_2_eax_disp8, sib_eax_2_ecx_disp8, sib_eax_2_edx_disp8, sib_eax_2_ebx_disp8, sib_eax_2_esp_disp8, sib_eax_2_ebp_disp8, sib_eax_2_esi_disp8, sib_eax_2_edi_disp8,
		sib_ecx_2_eax_disp8, sib_ecx_2_ecx_disp8, sib_ecx_2_edx_disp8, sib_ecx_2_ebx_disp8, sib_ecx_2_esp_disp8, sib_ecx_2_ebp_disp8, sib_ecx_2_esi_disp8, sib_ecx_2_edi_disp8,
		sib_edx_2_eax_disp8, sib_edx_2_ecx_disp8, sib_edx_2_edx_disp8, sib_edx_2_ebx_disp8, sib_edx_2_esp_disp8, sib_edx_2_ebp_disp8, sib_edx_2_esi_disp8, sib_edx_2_edi_disp8,
		sib_ebx_2_eax_disp8, sib_ebx_2_ecx_disp8, sib_ebx_2_edx_disp8, sib_ebx_2_ebx_disp8, sib_ebx_2_esp_disp8, sib_ebx_2_ebp_disp8, sib_ebx_2_esi_disp8, sib_ebx_2_edi_disp8,
		sib_ebp_2_eax_disp8, sib_ebp_2_ecx_disp8, sib_ebp_2_edx_disp8, sib_ebp_2_ebx_disp8, sib_ebp_2_esp_disp8, sib_ebp_2_ebp_disp8, sib_ebp_2_esi_disp8, sib_ebp_2_edi_disp8,
		sib_esi_2_eax_disp8, sib_esi_2_ecx_disp8, sib_esi_2_edx_disp8, sib_esi_2_ebx_disp8, sib_esi_2_esp_disp8, sib_esi_2_ebp_disp8, sib_esi_2_esi_disp8, sib_esi_2_edi_disp8,
		sib_edi_2_eax_disp8, sib_edi_2_ecx_disp8, sib_edi_2_edx_disp8, sib_edi_2_ebx_disp8, sib_edi_2_esp_disp8, sib_edi_2_ebp_disp8, sib_edi_2_esi_disp8, sib_edi_2_edi_disp8,

		sib_eax_4_eax_disp8, sib_eax_4_ecx_disp8, sib_eax_4_edx_disp8, sib_eax_4_ebx_disp8, sib_eax_4_esp_disp8, sib_eax_4_ebp_disp8, sib_eax_4_esi_disp8, sib_eax_4_edi_disp8,
		sib_ecx_4_eax_disp8, sib_ecx_4_ecx_disp8, sib_ecx_4_edx_disp8, sib_ecx_4_ebx_disp8, sib_ecx_4_esp_disp8, sib_ecx_4_ebp_disp8, sib_ecx_4_esi_disp8, sib_ecx_4_edi_disp8,
		sib_edx_4_eax_disp8, sib_edx_4_ecx_disp8, sib_edx_4_edx_disp8, sib_edx_4_ebx_disp8, sib_edx_4_esp_disp8, sib_edx_4_ebp_disp8, sib_edx_4_esi_disp8, sib_edx_4_edi_disp8,
		sib_ebx_4_eax_disp8, sib_ebx_4_ecx_disp8, sib_ebx_4_edx_disp8, sib_ebx_4_ebx_disp8, sib_ebx_4_esp_disp8, sib_ebx_4_ebp_disp8, sib_ebx_4_esi_disp8, sib_ebx_4_edi_disp8,
		sib_ebp_4_eax_disp8, sib_ebp_4_ecx_disp8, sib_ebp_4_edx_disp8, sib_ebp_4_ebx_disp8, sib_ebp_4_esp_disp8, sib_ebp_4_ebp_disp8, sib_ebp_4_esi_disp8, sib_ebp_4_edi_disp8,
		sib_esi_4_eax_disp8, sib_esi_4_ecx_disp8, sib_esi_4_edx_disp8, sib_esi_4_ebx_disp8, sib_esi_4_esp_disp8, sib_esi_4_ebp_disp8, sib_esi_4_esi_disp8, sib_esi_4_edi_disp8,
		sib_edi_4_eax_disp8, sib_edi_4_ecx_disp8, sib_edi_4_edx_disp8, sib_edi_4_ebx_disp8, sib_edi_4_esp_disp8, sib_edi_4_ebp_disp8, sib_edi_4_esi_disp8, sib_edi_4_edi_disp8,

		sib_eax_8_eax_disp8, sib_eax_8_ecx_disp8, sib_eax_8_edx_disp8, sib_eax_8_ebx_disp8, sib_eax_8_esp_disp8, sib_eax_8_ebp_disp8, sib_eax_8_esi_disp8, sib_eax_8_edi_disp8,
		sib_ecx_8_eax_disp8, sib_ecx_8_ecx_disp8, sib_ecx_8_edx_disp8, sib_ecx_8_ebx_disp8, sib_ecx_8_esp_disp8, sib_ecx_8_ebp_disp8, sib_ecx_8_esi_disp8, sib_ecx_8_edi_disp8,
		sib_edx_8_eax_disp8, sib_edx_8_ecx_disp8, sib_edx_8_edx_disp8, sib_edx_8_ebx_disp8, sib_edx_8_esp_disp8, sib_edx_8_ebp_disp8, sib_edx_8_esi_disp8, sib_edx_8_edi_disp8,
		sib_ebx_8_eax_disp8, sib_ebx_8_ecx_disp8, sib_ebx_8_edx_disp8, sib_ebx_8_ebx_disp8, sib_ebx_8_esp_disp8, sib_ebx_8_ebp_disp8, sib_ebx_8_esi_disp8, sib_ebx_8_edi_disp8,
		sib_ebp_8_eax_disp8, sib_ebp_8_ecx_disp8, sib_ebp_8_edx_disp8, sib_ebp_8_ebx_disp8, sib_ebp_8_esp_disp8, sib_ebp_8_ebp_disp8, sib_ebp_8_esi_disp8, sib_ebp_8_edi_disp8,
		sib_esi_8_eax_disp8, sib_esi_8_ecx_disp8, sib_esi_8_edx_disp8, sib_esi_8_ebx_disp8, sib_esi_8_esp_disp8, sib_esi_8_ebp_disp8, sib_esi_8_esi_disp8, sib_esi_8_edi_disp8,
		sib_edi_8_eax_disp8, sib_edi_8_ecx_disp8, sib_edi_8_edx_disp8, sib_edi_8_ebx_disp8, sib_edi_8_esp_disp8, sib_edi_8_ebp_disp8, sib_edi_8_esi_disp8, sib_edi_8_edi_disp8,

		sib_eax_eax_disp32, sib_eax_ecx_disp32, sib_eax_edx_disp32, sib_eax_ebx_disp32, sib_eax_esp_disp32, sib_eax_ebp_disp32, sib_eax_esi_disp32, sib_eax_edi_disp32,
		sib_ecx_eax_disp32, sib_ecx_ecx_disp32, sib_ecx_edx_disp32, sib_ecx_ebx_disp32, sib_ecx_esp_disp32, sib_ecx_ebp_disp32, sib_ecx_esi_disp32, sib_ecx_edi_disp32,
		sib_edx_eax_disp32, sib_edx_ecx_disp32, sib_edx_edx_disp32, sib_edx_ebx_disp32, sib_edx_esp_disp32, sib_edx_ebp_disp32, sib_edx_esi_disp32, sib_edx_edi_disp32,
		sib_ebx_eax_disp32, sib_ebx_ecx_disp32, sib_ebx_edx_disp32, sib_ebx_ebx_disp32, sib_ebx_esp_disp32, sib_ebx_ebp_disp32, sib_ebx_esi_disp32, sib_ebx_edi_disp32,
		sib_none_eax_disp32, sib_none_ecx_disp32, sib_none_edx_disp32, sib_none_ebx_disp32, sib_none_esp_disp32, sib_none_ebp_disp32, sib_none_esi_disp32, sib_none_edi_disp32,
		sib_ebp_eax_disp32, sib_ebp_ecx_disp32, sib_ebp_edx_disp32, sib_ebp_ebx_disp32, sib_ebp_esp_disp32, sib_ebp_ebp_disp32, sib_ebp_esi_disp32, sib_ebp_edi_disp32,
		sib_esi_eax_disp32, sib_esi_ecx_disp32, sib_esi_edx_disp32, sib_esi_ebx_disp32, sib_esi_esp_disp32, sib_esi_ebp_disp32, sib_esi_esi_disp32, sib_esi_edi_disp32,
		sib_edi_eax_disp32, sib_edi_ecx_disp32, sib_edi_edx_disp32, sib_edi_ebx_disp32, sib_edi_esp_disp32, sib_edi_ebp_disp32, sib_edi_esi_disp32, sib_edi_edi_disp32,

		sib_eax_2_eax_disp32, sib_eax_2_ecx_disp32, sib_eax_2_edx_disp32, sib_eax_2_ebx_disp32, sib_eax_2_esp_disp32, sib_eax_2_ebp_disp32, sib_eax_2_esi_disp32, sib_eax_2_edi_disp32,
		sib_ecx_2_eax_disp32, sib_ecx_2_ecx_disp32, sib_ecx_2_edx_disp32, sib_ecx_2_ebx_disp32, sib_ecx_2_esp_disp32, sib_ecx_2_ebp_disp32, sib_ecx_2_esi_disp32, sib_ecx_2_edi_disp32,
		sib_edx_2_eax_disp32, sib_edx_2_ecx_disp32, sib_edx_2_edx_disp32, sib_edx_2_ebx_disp32, sib_edx_2_esp_disp32, sib_edx_2_ebp_disp32, sib_edx_2_esi_disp32, sib_edx_2_edi_disp32,
		sib_ebx_2_eax_disp32, sib_ebx_2_ecx_disp32, sib_ebx_2_edx_disp32, sib_ebx_2_ebx_disp32, sib_ebx_2_esp_disp32, sib_ebx_2_ebp_disp32, sib_ebx_2_esi_disp32, sib_ebx_2_edi_disp32,
		sib_ebp_2_eax_disp32, sib_ebp_2_ecx_disp32, sib_ebp_2_edx_disp32, sib_ebp_2_ebx_disp32, sib_ebp_2_esp_disp32, sib_ebp_2_ebp_disp32, sib_ebp_2_esi_disp32, sib_ebp_2_edi_disp32,
		sib_esi_2_eax_disp32, sib_esi_2_ecx_disp32, sib_esi_2_edx_disp32, sib_esi_2_ebx_disp32, sib_esi_2_esp_disp32, sib_esi_2_ebp_disp32, sib_esi_2_esi_disp32, sib_esi_2_edi_disp32,
		sib_edi_2_eax_disp32, sib_edi_2_ecx_disp32, sib_edi_2_edx_disp32, sib_edi_2_ebx_disp32, sib_edi_2_esp_disp32, sib_edi_2_ebp_disp32, sib_edi_2_esi_disp32, sib_edi_2_edi_disp32,

		sib_eax_4_eax_disp32, sib_eax_4_ecx_disp32, sib_eax_4_edx_disp32, sib_eax_4_ebx_disp32, sib_eax_4_esp_disp32, sib_eax_4_ebp_disp32, sib_eax_4_esi_disp32, sib_eax_4_edi_disp32,
		sib_ecx_4_eax_disp32, sib_ecx_4_ecx_disp32, sib_ecx_4_edx_disp32, sib_ecx_4_ebx_disp32, sib_ecx_4_esp_disp32, sib_ecx_4_ebp_disp32, sib_ecx_4_esi_disp32, sib_ecx_4_edi_disp32,
		sib_edx_4_eax_disp32, sib_edx_4_ecx_disp32, sib_edx_4_edx_disp32, sib_edx_4_ebx_disp32, sib_edx_4_esp_disp32, sib_edx_4_ebp_disp32, sib_edx_4_esi_disp32, sib_edx_4_edi_disp32,
		sib_ebx_4_eax_disp32, sib_ebx_4_ecx_disp32, sib_ebx_4_edx_disp32, sib_ebx_4_ebx_disp32, sib_ebx_4_esp_disp32, sib_ebx_4_ebp_disp32, sib_ebx_4_esi_disp32, sib_ebx_4_edi_disp32,
		sib_ebp_4_eax_disp32, sib_ebp_4_ecx_disp32, sib_ebp_4_edx_disp32, sib_ebp_4_ebx_disp32, sib_ebp_4_esp_disp32, sib_ebp_4_ebp_disp32, sib_ebp_4_esi_disp32, sib_ebp_4_edi_disp32,
		sib_esi_4_eax_disp32, sib_esi_4_ecx_disp32, sib_esi_4_edx_disp32, sib_esi_4_ebx_disp32, sib_esi_4_esp_disp32, sib_esi_4_ebp_disp32, sib_esi_4_esi_disp32, sib_esi_4_edi_disp32,
		sib_edi_4_eax_disp32, sib_edi_4_ecx_disp32, sib_edi_4_edx_disp32, sib_edi_4_ebx_disp32, sib_edi_4_esp_disp32, sib_edi_4_ebp_disp32, sib_edi_4_esi_disp32, sib_edi_4_edi_disp32,

		sib_eax_8_eax_disp32, sib_eax_8_ecx_disp32, sib_eax_8_edx_disp32, sib_eax_8_ebx_disp32, sib_eax_8_esp_disp32, sib_eax_8_ebp_disp32, sib_eax_8_esi_disp32, sib_eax_8_edi_disp32,
		sib_ecx_8_eax_disp32, sib_ecx_8_ecx_disp32, sib_ecx_8_edx_disp32, sib_ecx_8_ebx_disp32, sib_ecx_8_esp_disp32, sib_ecx_8_ebp_disp32, sib_ecx_8_esi_disp32, sib_ecx_8_edi_disp32,
		sib_edx_8_eax_disp32, sib_edx_8_ecx_disp32, sib_edx_8_edx_disp32, sib_edx_8_ebx_disp32, sib_edx_8_esp_disp32, sib_edx_8_ebp_disp32, sib_edx_8_esi_disp32, sib_edx_8_edi_disp32,
		sib_ebx_8_eax_disp32, sib_ebx_8_ecx_disp32, sib_ebx_8_edx_disp32, sib_ebx_8_ebx_disp32, sib_ebx_8_esp_disp32, sib_ebx_8_ebp_disp32, sib_ebx_8_esi_disp32, sib_ebx_8_edi_disp32,
		sib_ebp_8_eax_disp32, sib_ebp_8_ecx_disp32, sib_ebp_8_edx_disp32, sib_ebp_8_ebx_disp32, sib_ebp_8_esp_disp32, sib_ebp_8_ebp_disp32, sib_ebp_8_esi_disp32, sib_ebp_8_edi_disp32,
		sib_esi_8_eax_disp32, sib_esi_8_ecx_disp32, sib_esi_8_edx_disp32, sib_esi_8_ebx_disp32, sib_esi_8_esp_disp32, sib_esi_8_ebp_disp32, sib_esi_8_esi_disp32, sib_esi_8_edi_disp32,
		sib_edi_8_eax_disp32, sib_edi_8_ecx_disp32, sib_edi_8_edx_disp32, sib_edi_8_ebx_disp32, sib_edi_8_esp_disp32, sib_edi_8_ebp_disp32, sib_edi_8_esi_disp32, sib_edi_8_edi_disp32,

		// TODO: Long Mode.

		MemEnd = 0x1000,

	};

	/// <summary>
	/// The maximum number of parameters for the instruction. In the manual, there are 4 max parameters in the tables, but we will be reinsured. 
	/// </summary>
	constexpr auto ParamsMax = 8;

	/// <summary>
	/// The maximum size of all prefixes. (bytes)
	/// </summary>
	constexpr auto PrefixMaxSize = 16;

	/// <summary>
	/// Maximum instruction size excluding prefixes. (bytes)
	/// </summary>
	constexpr auto InstrMaxSize = 16;

	/// <summary>
	/// The structure contains all information about the instruction, including possible prefixes and a parameter list.
	/// This is a deliberate abstraction from the very alien definition of ModRM. All possible combinations of parameters are specified by the Param enumeration.
	/// </summary>
	struct AnalyzeInfo
	{
		Category category;		// It is set by the analyzer, for other cases it is not necessary to set it. 

		// When analyzing the flow of instructions, prefixes are separated from instruction,
		// so the total size of the code batch will be equal to the size of all prefixes + the size of the instruction itself. 

		Prefix prefixes[PrefixMaxSize];
		size_t numPrefixes;
		uint8_t prefixBytes[PrefixMaxSize];
		size_t prefixSize;

		Instruction instr;
		uint8_t instrBytes[InstrMaxSize];
		size_t instrSize;

		Param params[ParamsMax];
		size_t numParams;

		union
		{
			uint8_t disp8;
			uint16_t disp16;
			uint32_t disp32;
			uint64_t disp64;
		} Disp;

		union
		{
			uint8_t uimm8;
			uint16_t uimm16;
			uint32_t uimm32;
			uint64_t uimm64;

			int8_t simm8;
			int16_t simm16;
			int32_t simm32;
			int64_t simm64;
		} Imm;
	};

}
